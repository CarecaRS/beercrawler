{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4673e7ae",
   "metadata": {},
   "source": [
    "# Grocery Store Prices Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a40515",
   "metadata": {},
   "source": [
    "I originally did this to track beer prices near me. It can be tweaked to fetch the prices from other products aswell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa4dc7",
   "metadata": {},
   "source": [
    "### To-do list:\n",
    "- Date as index (better to compare prices later)\n",
    "- Add notifications by e-mail (gmail-send-stuff, I don't remember exactly what package - see TouringTrade)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5487cd53",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820523bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procura(items:list, produto):\n",
    "    \"\"\"\n",
    "    Args: items: list, lista de produtos a se verificar\n",
    "          produtos: DataFrame, banco de dados que contem os produtos que foram obtidos e terão os preços conferidos\n",
    "\n",
    "    Returns: NA\n",
    "    \"\"\"\n",
    "\n",
    "    for i in items:\n",
    "        if 'milka' in i.lower():\n",
    "            searchfor = 1\n",
    "        elif 'guinness' in i.lower():\n",
    "            searchfor = 2\n",
    "    \n",
    "    \n",
    "    if searchfor == 1:\n",
    "        try:\n",
    "            encontrado = 0\n",
    "            for item in items:\n",
    "                index = 0\n",
    "                for stock in produto.Chocolate:\n",
    "                    if item in stock.lower():\n",
    "                        print(f'Em {produto['Data'][index]}, no {produto.Local[index]}: {stock}, {produto.Embalagem[index]}, por {produto['Custo de compra'][index]}€, preço por kg {produto['Preço por kg/l'][index]}€.')\n",
    "                        encontrado = 1\n",
    "                    index += 1\n",
    "\n",
    "            if encontrado == 0:\n",
    "                print('Não encontrei nenhum dos chocolates.')\n",
    "        except:\n",
    "            print('Algo deu errado. Algum erro não previsto na verificação dos chocolates.')\n",
    "\n",
    "\n",
    "    elif searchfor == 2:\n",
    "        try:\n",
    "            encontrado = 0\n",
    "            for item in items:\n",
    "                index = 0\n",
    "                for stock in produto.Cerveja:\n",
    "                    if item in stock.lower():\n",
    "                        print(f'Em {produto['Data'][index]}, no {produto.Local[index]}: {stock}, {produto.Embalagem[index]}, por {produto['Custo de compra'][index]}€, preço por litro {produto['Preço por kg/l'][index]}€.')\n",
    "                        encontrado = 1\n",
    "                    index += 1\n",
    "\n",
    "            if encontrado == 0:\n",
    "                print('Não encontrei nenhuma das cervejas.')\n",
    "        except:\n",
    "            print('Algo deu errado. Algum erro não previsto na verificação das cervejas.')\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('Não sei o que fazer. Não encontrei nem Milka nem Guinness nas tuas listas. Te vira.')\n",
    "    \n",
    "\n",
    "def busca_continente():\n",
    "    \"\"\"\n",
    "    Args: none\n",
    "\n",
    "    Returns: dois DataFrames, o primeiro contendo a relação das cervejas pesquisadas no site e o segundo\n",
    "             contendo os chocolates\n",
    "    \"\"\"\n",
    "    # Imports\n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup\n",
    "    from datetime import datetime\n",
    "    from selenium import webdriver\n",
    "    from time import sleep\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "    # Setting supermarket URLs\n",
    "    urls_cont = ['https://www.continente.pt/bebidas-e-garrafeira/cervejas-e-sidras/cerveja-estrangeira-e-artesanal/',\n",
    "                'https://www.continente.pt/bebidas-e-garrafeira/cervejas-e-sidras/cerveja-tradicional/']\n",
    "\n",
    "    choc_cont = ['https://www.continente.pt/mercearia/chocolate-gomas-e-rebucados/chocolates/?start=0&srule=COL-Continente&pmin=0.01']\n",
    "\n",
    "    # Creates empty DataFrames in order to properly receive the data\n",
    "    print('Creating DataFrames and setting some configs...')\n",
    "    cevas = pd.DataFrame()\n",
    "    chocolates = pd.DataFrame()\n",
    "    \n",
    "    # Setting some configs\n",
    "    mercado = 'Continente'\n",
    "    data = datetime.now().strftime('%d-%m-%Y')\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "\n",
    "    # Get the response from the given URLs for beers in Continente.pt\n",
    "    print('Starting to gather beer information...')\n",
    "    for url in urls_cont:\n",
    "        print(f'\\nBeginning the scrap on {url}')\n",
    "    # Using Selenium to fetch page html and deal with lazyloading\n",
    "        try:\n",
    "            # Driver accesses URL(s)\n",
    "            driver = webdriver.Firefox(options=options)\n",
    "            print('Driver ready. Accessing website, just a second please.')\n",
    "            driver.get(url)\n",
    "\n",
    "            # Get rid of cookies popup (or whatever the name is pop-up, poupup...)\n",
    "            print('Closing cookies popup...')\n",
    "            driver.find_element(By.ID, 'CybotCookiebotDialogBodyLevelButtonCustomize').click()\n",
    "            sleep(1) # these sleep are just for it isn't given away that is a crawler 'clicking'\n",
    "            driver.find_element(By.ID, 'CybotCookiebotDialogBodyButtonDecline').click()\n",
    "            sleep(1)\n",
    "            print('...done.')\n",
    "\n",
    "            # Loads all the lazyloading\n",
    "            print('Dealing with lazyloading...')\n",
    "            while True:\n",
    "                try:\n",
    "                    WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.XPATH, \"//button[@class='button button--secondary col-button col-button--secondary-dark search-view-more-products-button js-show-more-products' and contains(., 'Ver mais produtos')]\"))).click()\n",
    "                except Exception as e:\n",
    "                    break\n",
    "            print('...done.')\n",
    "\n",
    "            # With the lazyloading already loaded, registers the html code\n",
    "            html = driver.page_source\n",
    "            print('HTML code at hand, closing driver.')\n",
    "\n",
    "            # And closes the headless browser\n",
    "            driver.quit()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Algo ocorre: {e}')\n",
    "            driver.quit()\n",
    "        \n",
    "\n",
    "        print('Translating HTML...')\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # With the response, fetch all the available beers names, prices per liter, cost of purchase and packaging\n",
    "        print('Fetching brands, names, prices per liter and total prices...')\n",
    "        beers = soup.select('h2')\n",
    "        prices_pl = soup.select('div[class=\"pwc-tile--price-secondary\"]')\n",
    "        totals = soup.select('span[class=\"pwc-tile--price-primary\"]')\n",
    "        embalagem = soup.select('p[class=\"pwc-tile--quantity\"]')\n",
    "\n",
    "        # Creating empty lists to hold site beer names, prices (liter and absolute) and packaging\n",
    "        nomes = []\n",
    "        precos_litro = []\n",
    "        p_total = []\n",
    "        pack = []\n",
    "\n",
    "        # Filtering the name of the website product\n",
    "        try:\n",
    "            for i in beers:\n",
    "                nomes.append(\"Cerveja \"+i.get_text().split('com Álcool')[1].lstrip().rstrip())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Filtering the prices per liter for each product\n",
    "        for price in prices_pl:\n",
    "            precos_litro.append(price.get_text().split('€')[0].replace(',', '.').lstrip().rstrip())\n",
    "\n",
    "        # Filtering the cost to buy each product\n",
    "        for price in totals:\n",
    "            p_total.append(price.get_text().split('€')[0].replace(',', '.').lstrip().rstrip())\n",
    "\n",
    "        # Filtering the product packaging type\n",
    "        for item in embalagem:\n",
    "            pack.append(item.get_text().lstrip().rstrip()) \n",
    "\n",
    "        print('...done. Updating the DataFrame with these informations...')\n",
    "        ### Creating a DataFrame with all this information\n",
    "        # Setting column names\n",
    "        colunas = ['Data', 'Local', 'Produto', 'Embalagem', 'Preço por kg/l', 'Custo de compra']\n",
    "\n",
    "        # Joining most lists as a DataFrame\n",
    "        cervejas = pd.DataFrame([nomes, pack, precos_litro, p_total]).T\n",
    "\n",
    "        # Concatenating the date and time (just on the first entry)\n",
    "        cervejas = pd.concat([pd.Series(data), pd.Series(mercado), cervejas], ignore_index=True, axis=1)\n",
    "\n",
    "        # Renaming the columns\n",
    "        cervejas.columns = colunas\n",
    "\n",
    "        # Converting prices to float (they're objects until now)\n",
    "        cervejas['Preço por kg/l'] = cervejas['Preço por kg/l'].astype('float')\n",
    "        cervejas['Custo de compra'] = cervejas['Custo de compra'].astype('float')\n",
    "\n",
    "        # Filling the date and supermarket columns\n",
    "        cervejas['Data'] = pd.to_datetime(data)\n",
    "        cervejas['Local'] = mercado\n",
    "\n",
    "        # Concat?\n",
    "        cevas = pd.concat([cevas, cervejas], axis=0, ignore_index=True)\n",
    "        cevas.dropna(inplace=True)\n",
    "        cevas.drop_duplicates(inplace=True)\n",
    "        print('...done.')\n",
    "\n",
    "    print('\\nBeers done. Starting to fetch chocolates information, please wait just a little bit more.')\n",
    "    for url in choc_cont:\n",
    "        print(f'\\nBeginning the scrap on {url}')\n",
    "        # Using Selenium to fetch page html and deal with lazyloading\n",
    "        try:\n",
    "            driver = webdriver.Firefox(options=options)\n",
    "            print('Driver ready. Accessing website, just a second please.')\n",
    "            # Driver accesses URL(s)            \n",
    "            driver.get(url)\n",
    "\n",
    "            # Get rid of cookies popup (or whatever the name is pop-up, poupup...)\n",
    "            print('Closing cookies popup...')\n",
    "            driver.find_element(By.ID, 'CybotCookiebotDialogBodyLevelButtonCustomize').click()\n",
    "            sleep(1) # these sleep are just for it isn't given away that is a crawler 'clicking'\n",
    "            driver.find_element(By.ID, 'CybotCookiebotDialogBodyButtonDecline').click()\n",
    "            print('...done.')\n",
    "            sleep(1)\n",
    "\n",
    "            # Loads all the lazyloading\n",
    "            print('Dealing with lazyloading...')\n",
    "            while True:\n",
    "                try:\n",
    "                    WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.XPATH, \"//button[@class='button button--secondary col-button col-button--secondary-dark search-view-more-products-button js-show-more-products' and contains(., 'Ver mais produtos')]\"))).click()\n",
    "                except Exception as e:\n",
    "                    break\n",
    "            print('...done.')\n",
    "            \n",
    "            # With the lazyloading already loaded, registers the html code\n",
    "            html = driver.page_source\n",
    "            print('HTML code at hand, closing driver.')\n",
    "\n",
    "            # And closes the headless browser\n",
    "            driver.quit()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Algo ocorre: {e}')\n",
    "            driver.quit()\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # With the response, get all the available beers names, prices per liter, cost of purchase and packaging\n",
    "        print('Fetching brands, chocolate names, prices per kg and total prices...')\n",
    "        chocolate = soup.select('h2')\n",
    "        prices_pl = soup.select('div[class=\"pwc-tile--price-secondary\"]')\n",
    "        totals = soup.select('span[class=\"pwc-tile--price-primary\"]')\n",
    "        embalagem = soup.select('p[class=\"pwc-tile--quantity\"]')\n",
    "\n",
    "        # Creating empty lists to hold site chocolate names, prices (kg and absolute) and packaging\n",
    "        nomes = []\n",
    "        precos_kg = []\n",
    "        p_total = []\n",
    "        pack = []\n",
    "\n",
    "        # Filtering the name of the website product\n",
    "        for i in chocolate:\n",
    "            nomes.append(i.get_text().lstrip().rstrip())\n",
    "\n",
    "        # Filtering the prices per kg for each product\n",
    "        for price in prices_pl:\n",
    "            precos_kg.append(price.get_text().split('€')[0].replace(',', '.').lstrip().rstrip())\n",
    "\n",
    "        # Filtering the cost to buy each product\n",
    "        for price in totals:\n",
    "            p_total.append(price.get_text().split('€')[0].replace(',', '.').lstrip().rstrip())\n",
    "\n",
    "        # Filtering the product packaging type\n",
    "        for item in embalagem:\n",
    "            pack.append(item.get_text().lstrip().rstrip().split(' ')[1])\n",
    "\n",
    "        print('...done. Updating the DataFrame with these informations...')\n",
    "\n",
    "        ### Creating a DataFrame with all this information\n",
    "        # Setting column names (the date is already stated before)\n",
    "        colunas = ['Data', 'Local', 'Produto', 'Embalagem', 'Preço por kg/l', 'Custo de compra']\n",
    "\n",
    "        # Joining most lists as a DataFrame\n",
    "        chocs = pd.DataFrame([nomes, pd.to_numeric(pack, errors='coerce'), precos_kg, p_total]).T\n",
    "\n",
    "        # Concatenating the date and time (just on the first entry)\n",
    "        chocs = pd.concat([pd.Series(data), pd.Series(mercado), chocs], ignore_index=True, axis=1)\n",
    "\n",
    "        # Renaming the columns\n",
    "        chocs.columns = colunas\n",
    "\n",
    "        # Cleaning some '' information (NaN value not NaN)\n",
    "        mask = chocs['Preço por kg/l'] == ''\n",
    "        idx = chocs.loc[mask].index.values\n",
    "        chocs.drop(idx, inplace=True)\n",
    "\n",
    "        mask = chocs['Custo de compra'] == ''\n",
    "        idx = chocs.loc[mask].index.values\n",
    "        chocs.drop(idx, inplace=True)\n",
    "\n",
    "        # Converting prices to float (they're objects until now)\n",
    "        chocs['Preço por kg/l'] = chocs['Preço por kg/l'].astype('float')\n",
    "        chocs['Custo de compra'] = chocs['Custo de compra'].astype('float')\n",
    "        chocs['Embalagem'] = chocs['Embalagem']/1000\n",
    "        \n",
    "\n",
    "        # Filling the date and supermarket columns\n",
    "        chocs['Data'] = pd.to_datetime(data)\n",
    "        chocs['Local'] = mercado\n",
    "\n",
    "        # Concat everything, cleaning duplicates, reseting index\n",
    "        chocolates = pd.concat([chocolates, chocs], axis=0, ignore_index=True)\n",
    "        chocolates.dropna(inplace=True)\n",
    "        chocolates.drop_duplicates(inplace=True)\n",
    "        chocolates.reset_index(drop=True, inplace=True)\n",
    "        print('...done.')\n",
    "    \n",
    "    print(f'\\nScrapping on {mercado} completed successfully. Found {cevas.shape[0]} beers and {chocolates.shape[0]} chocolates.')\n",
    "\n",
    "    return cevas, chocolates\n",
    "\n",
    "\n",
    "def busca_pingodoce():\n",
    "    \"\"\"\n",
    "    Args: none\n",
    "\n",
    "    Returns: dois DataFrames, o primeiro contendo a relação das cervejas pesquisadas no site e o segundo\n",
    "             contendo os chocolates\n",
    "    \"\"\"\n",
    "    # Imports\n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup\n",
    "    from datetime import datetime\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.keys import Keys\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from time import sleep\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "    # Setting supermarket URLs\n",
    "    urls_pingo = ['https://www.pingodoce.pt/on/demandware.store/Sites-pingo-doce-Site/default/Search-Show?cgid=ec_cervejasestrangeiras_1500_200',\n",
    "                'https://www.pingodoce.pt/on/demandware.store/Sites-pingo-doce-Site/default/Search-Show?cgid=ec_cervejasnacionais_1500_100']\n",
    "\n",
    "    choc_pingo = ['https://www.pingodoce.pt/on/demandware.store/Sites-pingo-doce-Site/default/Search-Show?cgid=ec_tabletes_1200_300_100']\n",
    "\n",
    "    # Creates empty DataFrames in order to properly receive the data\n",
    "    print('Creating DataFrames and setting some configs...')\n",
    "    cevas = pd.DataFrame()\n",
    "    chocolates = pd.DataFrame()\n",
    "\n",
    "    # Setting some configs\n",
    "    mercado = 'Pingo Doce'\n",
    "    data = datetime.now().strftime('%d-%m-%Y')\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "\n",
    "    # Get the response from the given URLs for beers in pingodoce.pt\n",
    "    print('Starting to gather beer information...')\n",
    "    for url in urls_pingo:\n",
    "        print(f'\\nBeginning the scrap on {url}')\n",
    "    # Using Selenium to fetch page html and deal with lazyloading\n",
    "        try:\n",
    "            # Driver accesses URL(s)\n",
    "            driver = webdriver.Firefox(options=options)\n",
    "            print('Driver ready. Accessing website, just a second please.')\n",
    "            driver.get(url)\n",
    "            sleep(3)\n",
    "\n",
    "            # Get rid of cookies popup (or whatever the name is pop-up, poupup...)\n",
    "            print('Closing cookies popup...')\n",
    "            WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \".onetrust-close-btn-ui\"))).click()\n",
    "            print('...done.')\n",
    "            sleep(3)\n",
    "\n",
    "            # Loads all the lazyloading\n",
    "            try:\n",
    "                print('Dealing with lazyloading...')\n",
    "                WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.col-sm-4\"))).click()\n",
    "                sleep(2)\n",
    "\n",
    "                stopScrolling = 0\n",
    "                while True:\n",
    "                    stopScrolling += 1\n",
    "                    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "                    sleep(0.5)\n",
    "                    if stopScrolling > 12:\n",
    "                        break\n",
    "                print('...done.')\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Erro interno: {e}')\n",
    "                break\n",
    "    \n",
    "            \n",
    "            # With the lazyloading already loaded, registers the html code\n",
    "            html = driver.page_source\n",
    "            print('HTML code at hand, closing driver.')\n",
    "\n",
    "            # And closes the headless browser\n",
    "            driver.quit()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Algo ocorre: {e}')\n",
    "            driver.quit()\n",
    "\n",
    "        print('Translating HTML...')\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # With the response, fetch all the available beers names, prices per liter, cost of purchase and packing\n",
    "        print('Fetching brands, names, prices per liter and total prices...')\n",
    "        marca = soup.select('div[class=\"product-brand-name\"]')\n",
    "        beers = soup.select('div[class=\"product-name-link\"]')\n",
    "        prices_pl = soup.select('div[class=\"product-unit\"]')\n",
    "        totals = soup.select('div[class=\"product-price\"]')\n",
    "\n",
    "\n",
    "        # Creating empty lists to hold site beer names, prices (liter and absolute) and packaging\n",
    "        nomes_orig = []\n",
    "        marcas = []\n",
    "        precos_litro = []\n",
    "        p_total = []\n",
    "        pack = []\n",
    "\n",
    "        # Filtering the name of the website product\n",
    "        try:\n",
    "            for i in beers:\n",
    "                nomes_orig.append(\"Cerveja \"+i.get_text().split('com Álcool')[1].lstrip().rstrip())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Filtering the name of the product brand\n",
    "        for i in marca:\n",
    "            marcas.append(i.get_text().lstrip().rstrip())\n",
    "\n",
    "        # Filtering the prices per liter for each product\n",
    "        for price in prices_pl:\n",
    "            precos_litro.append(price.get_text().split('|')[1].lstrip().rstrip().split(' ')[0].replace(',', '.'))\n",
    "\n",
    "        # Filtering the cost to buy each product\n",
    "        for price in totals:\n",
    "            p_total.append(price.get_text().split('€')[0].replace(',', '.').lstrip().rstrip())\n",
    "\n",
    "        # Filtering the product packaging type\n",
    "        for item in prices_pl:\n",
    "            pack.append(item.get_text().split('|')[0].lstrip().rstrip().split(' ')[0])\n",
    "\n",
    "        # Using Pandas to create a new list for the names + brand of each item\n",
    "        temp = pd.DataFrame([nomes_orig, marcas]).T\n",
    "        temp['Unidos'] = temp[0] + str(' ') + temp[1]\n",
    "        nomes = temp.Unidos.to_list()\n",
    "\n",
    "        print('...done. Updating the DataFrame with these informations...')\n",
    "        ### Creating a DataFrame with all this information\n",
    "        # Setting column names\n",
    "        colunas = ['Data', 'Local', 'Produto', 'Embalagem', 'Preço por kg/l', 'Custo de compra']\n",
    "\n",
    "        # Joining most lists as a DataFrame\n",
    "        cervejas = pd.DataFrame([nomes, pack, precos_litro, p_total]).T\n",
    "\n",
    "        # Concatenating the date and time (just on the first entry)\n",
    "        cervejas = pd.concat([pd.Series(data), pd.Series(mercado), cervejas], ignore_index=True, axis=1)\n",
    "\n",
    "        # Renaming the columns\n",
    "        cervejas.columns = colunas\n",
    "\n",
    "        # Converting prices to float (they're objects until now)\n",
    "        cervejas['Preço por kg/l'] = cervejas['Preço por kg/l'].astype('float')\n",
    "        cervejas['Custo de compra'] = cervejas['Custo de compra'].astype('float')\n",
    "        cervejas['Embalagem'] = cervejas['Embalagem'].astype('float')\n",
    "\n",
    "        # Filling the date and supermarket columns\n",
    "        cervejas['Data'] = pd.to_datetime(data)\n",
    "        cervejas['Local'] = mercado\n",
    "\n",
    "        # Concat\n",
    "        cevas = pd.concat([cevas, cervejas], axis=0)\n",
    "        cevas.dropna(inplace=True)\n",
    "        cevas.drop_duplicates(inplace=True)\n",
    "        cevas.reset_index(inplace=True, drop=True)\n",
    "        print('...done.')\n",
    "\n",
    "    print('\\nBeers done. Starting to fetch chocolates information, please wait just a little bit more.')\n",
    "\n",
    "    for url in choc_pingo:\n",
    "        print(f'\\nBeginning the scrap on {url}')\n",
    "        # Using Selenium to fetch page html and deal with lazyloading\n",
    "        try:\n",
    "            # Driver accesses URL(s)\n",
    "            driver = webdriver.Firefox(options=options)\n",
    "            print('Driver ready. Accessing website, just a second please.')\n",
    "            driver.get(url)\n",
    "            sleep(3)\n",
    "\n",
    "            # Get rid of cookies popup (or whatever the name is pop-up, poupup...)\n",
    "            print('Closing cookies popup...')\n",
    "            WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \".onetrust-close-btn-ui\"))).click()\n",
    "            print('...done.')\n",
    "            sleep(3) \n",
    "\n",
    "            # Loads all the lazyloading\n",
    "            try:\n",
    "                print('Dealing with lazyloading...')\n",
    "                WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.col-sm-4\"))).click()\n",
    "                sleep(2)\n",
    "                #driver.find_element(By.ID, 'header-search-bar').send_keys(Keys.END)\n",
    "                #sleep(2)\n",
    "                # scrolling down slowly\n",
    "                stopScrolling = 0\n",
    "                while True:\n",
    "                    stopScrolling += 1\n",
    "                    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "                    sleep(0.5)\n",
    "                    if stopScrolling > 12:\n",
    "                        break\n",
    "                print('...done.')\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Erro interno: {e}')\n",
    "                break\n",
    "    \n",
    "            \n",
    "            # With the lazyloading already loaded, registers the html code\n",
    "            html = driver.page_source\n",
    "            print('HTML code at hand, closing driver.')\n",
    "\n",
    "            # And closes the headless browser\n",
    "            driver.quit()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Algo ocorre: {e}')\n",
    "            driver.quit()\n",
    "\n",
    "        print('Translating HTML...')\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # With the response, get all the available beers names, prices per liter, cost of purchase and packaging\n",
    "        print('Fetching brands, chocolate names, prices per kg and total prices...')\n",
    "        marca = soup.select('div[class=\"product-brand-name\"]')\n",
    "        chocolate = soup.select('div[class=\"product-name-link\"]')\n",
    "        prices_kg = soup.select('div[class=\"product-unit\"]')\n",
    "        totals = soup.select('div[class=\"product-price\"]')\n",
    "\n",
    "        # Creating empty lists to hold site chocolate names, prices (kg and absolute) and packaging\n",
    "        nomes_orig = []\n",
    "        marcas = []\n",
    "        precos_kg = []\n",
    "        p_total = []\n",
    "        pack = []\n",
    "\n",
    "        # Filtering the name of the website product\n",
    "        for i in chocolate:\n",
    "            nomes_orig.append(i.get_text().lstrip().rstrip())\n",
    "\n",
    "        # Filtering the name of the product brand\n",
    "        for i in marca:\n",
    "            marcas.append(i.get_text().lstrip().rstrip())\n",
    "\n",
    "        # Filtering the prices per kg for each product\n",
    "        for price in prices_kg:\n",
    "            precos_kg.append(price.get_text().split('|')[1].lstrip().rstrip().split(' ')[0].replace(',', '.'))\n",
    "\n",
    "        # Filtering the cost to buy each product\n",
    "        for price in totals:\n",
    "            p_total.append(price.get_text().split('€')[0].replace(',', '.').lstrip().rstrip())\n",
    "\n",
    "        # Filtering the product packaging type\n",
    "        for item in prices_kg:\n",
    "            pack.append(item.get_text().split('|')[0].lstrip().rstrip().split(' ')[0])\n",
    "\n",
    "        # Using Pandas to create a new list for the names + brand of each item\n",
    "        temp = pd.DataFrame([nomes_orig, marcas]).T\n",
    "        temp['Unidos'] = temp[0] + str(' ') + temp[1]\n",
    "        nomes = temp.Unidos.to_list()\n",
    "\n",
    "        print('...done. Updating the DataFrame with these informations...')\n",
    "\n",
    "        ### Creating a DataFrame with all this information\n",
    "        # Setting column names (the date is already stated before)\n",
    "        colunas = ['Data', 'Local', 'Produto', 'Embalagem', 'Preço por kg/l', 'Custo de compra']\n",
    "\n",
    "        # Joining most lists as a DataFrame\n",
    "        chocs = pd.DataFrame([nomes, pack, precos_kg, p_total]).T\n",
    "\n",
    "        # Concatenating the date and time (just on the first entry)\n",
    "        chocs = pd.concat([pd.Series(data), pd.Series(mercado), chocs], ignore_index=True, axis=1)\n",
    "\n",
    "        # Renaming the columns\n",
    "        chocs.columns = colunas\n",
    "\n",
    "        # Cleaning some '' information (NaN value not NaN)\n",
    "        mask = chocs['Preço por kg/l'] == ''\n",
    "        idx = chocs.loc[mask].index.values\n",
    "        chocs.drop(idx, inplace=True)\n",
    "\n",
    "        mask = chocs['Custo de compra'] == ''\n",
    "        idx = chocs.loc[mask].index.values\n",
    "        chocs.drop(idx, inplace=True)\n",
    "\n",
    "        # Converting prices to float (they're objects until now)\n",
    "        chocs['Preço por kg/l'] = chocs['Preço por kg/l'].astype('float')\n",
    "        chocs['Custo de compra'] = chocs['Custo de compra'].astype('float')\n",
    "        chocs['Embalagem'] = chocs['Embalagem'].astype('float')\n",
    "\n",
    "        # Filling the date and supermarket columns\n",
    "        chocs['Data'] = pd.to_datetime(data)\n",
    "        chocs['Local'] = mercado\n",
    "\n",
    "        # Concat everything, cleaning duplicates, reseting index\n",
    "        chocolates = pd.concat([chocolates, chocs], axis=0, ignore_index=True)\n",
    "        chocolates.dropna(inplace=True)\n",
    "        chocolates.drop_duplicates(inplace=True)\n",
    "        chocolates.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        print('...done.')\n",
    "\n",
    "    print(f'\\nScrapping on {mercado} completed successfully. Found {cevas.shape[0]} beers and {chocolates.shape[0]} chocolates.')\n",
    "\n",
    "    return cevas, chocolates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b9424",
   "metadata": {},
   "source": [
    "The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6263e55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataFrames and setting some configs...\n",
      "Starting to gather beer information...\n",
      "\n",
      "Beginning the scrap on https://www.continente.pt/bebidas-e-garrafeira/cervejas-e-sidras/cerveja-estrangeira-e-artesanal/\n",
      "Driver ready. Accessing website, just a second please.\n",
      "Closing cookies popup...\n",
      "...done.\n",
      "Dealing with lazyloading...\n",
      "...done.\n",
      "HTML code at hand, closing driver.\n",
      "Translating HTML...\n",
      "Fetching brands, names, prices per liter and total prices...\n",
      "...done. Updating the DataFrame with these informations...\n",
      "...done.\n",
      "\n",
      "Beginning the scrap on https://www.continente.pt/bebidas-e-garrafeira/cervejas-e-sidras/cerveja-tradicional/\n",
      "Driver ready. Accessing website, just a second please.\n",
      "Closing cookies popup...\n",
      "...done.\n",
      "Dealing with lazyloading...\n",
      "...done.\n",
      "HTML code at hand, closing driver.\n",
      "Translating HTML...\n",
      "Fetching brands, names, prices per liter and total prices...\n",
      "...done. Updating the DataFrame with these informations...\n",
      "...done.\n",
      "\n",
      "Beers done. Starting to fetch chocolates information, please wait just a little bit more.\n",
      "\n",
      "Beginning the scrap on https://www.continente.pt/mercearia/chocolate-gomas-e-rebucados/chocolates/?start=0&srule=COL-Continente&pmin=0.01\n",
      "Driver ready. Accessing website, just a second please.\n",
      "Closing cookies popup...\n",
      "...done.\n",
      "Dealing with lazyloading...\n",
      "...done.\n",
      "HTML code at hand, closing driver.\n",
      "Fetching brands, chocolate names, prices per kg and total prices...\n",
      "...done. Updating the DataFrame with these informations...\n",
      "...done.\n",
      "\n",
      "Scrapping on Continente completed successfully. Found 87 beers and 155 chocolates.\n",
      "Creating DataFrames and setting some configs...\n",
      "Starting to gather beer information...\n",
      "\n",
      "Beginning the scrap on https://www.pingodoce.pt/on/demandware.store/Sites-pingo-doce-Site/default/Search-Show?cgid=ec_cervejasestrangeiras_1500_200\n",
      "Driver ready. Accessing website, just a second please.\n",
      "Closing cookies popup...\n",
      "...done.\n",
      "Dealing with lazyloading...\n",
      "...done.\n",
      "HTML code at hand, closing driver.\n",
      "Translating HTML...\n",
      "Fetching brands, names, prices per liter and total prices...\n",
      "...done. Updating the DataFrame with these informations...\n",
      "...done.\n",
      "\n",
      "Beginning the scrap on https://www.pingodoce.pt/on/demandware.store/Sites-pingo-doce-Site/default/Search-Show?cgid=ec_cervejasnacionais_1500_100\n",
      "Driver ready. Accessing website, just a second please.\n",
      "Closing cookies popup...\n",
      "...done.\n",
      "Dealing with lazyloading...\n",
      "...done.\n",
      "HTML code at hand, closing driver.\n",
      "Translating HTML...\n",
      "Fetching brands, names, prices per liter and total prices...\n",
      "...done. Updating the DataFrame with these informations...\n",
      "...done.\n",
      "\n",
      "Beers done. Starting to fetch chocolates information, please wait just a little bit more.\n",
      "\n",
      "Beginning the scrap on https://www.pingodoce.pt/on/demandware.store/Sites-pingo-doce-Site/default/Search-Show?cgid=ec_tabletes_1200_300_100\n",
      "Driver ready. Accessing website, just a second please.\n",
      "Closing cookies popup...\n",
      "...done.\n",
      "Dealing with lazyloading...\n",
      "...done.\n",
      "HTML code at hand, closing driver.\n",
      "Translating HTML...\n",
      "Fetching brands, chocolate names, prices per kg and total prices...\n",
      "...done. Updating the DataFrame with these informations...\n",
      "...done.\n",
      "\n",
      "Scrapping on Pingo Doce completed successfully. Found 44 beers and 84 chocolates.\n"
     ]
    }
   ],
   "source": [
    "# Items that I want to track\n",
    "my_beers = ['coruja india pale ale', 'guinness', 'franziskaner', 'estrella', 'erdinger', 'benediktiner']\n",
    "my_choc = ['milka', 'biglicious', 'biiig'] # biglicious e biiig são as barras de 300g do Continente/Pingo Doce\n",
    "\n",
    "cervejas_c, chocolates_c = busca_continente()\n",
    "cervejas_p, chocolates_p = busca_pingodoce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e45f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    print('Trying local historical files...')\n",
    "    pingodoce = pd.read_parquet('hist/pingodoce.parquet')\n",
    "    print('PingoDoce history found.')\n",
    "except:\n",
    "    print('PingoDoce has no historical data, creating new one.')\n",
    "    pingodoce = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    print('Trying local historical files...')\n",
    "    continente = pd.read_parquet('hist/continente.parquet')\n",
    "    print('Continente history found.')\n",
    "except:\n",
    "    print('Continente has no historical data, creating new one.')\n",
    "    continente = pd.DataFrame()\n",
    "\n",
    "pingodoce = pd.concat([pingodoce, chocolates_p, cervejas_p], ignore_index=True)\n",
    "continente = pd.concat([continente, chocolates_c, cervejas_c], ignore_index=True)\n",
    "\n",
    "pingodoce.to_parquet('hist/pingodoce.parquet')\n",
    "continente.to_parquet('hist/continente.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f273557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Local</th>\n",
       "      <th>Produto</th>\n",
       "      <th>Embalagem</th>\n",
       "      <th>Preço por kg/l</th>\n",
       "      <th>Custo de compra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2026-10-02</td>\n",
       "      <td>Pingo Doce</td>\n",
       "      <td>Tablete de Chocolate Biiig Amendoim Pingo Doce</td>\n",
       "      <td>0.295</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2026-10-02</td>\n",
       "      <td>Pingo Doce</td>\n",
       "      <td>Tablete de Chocolate Biiig Biscuit Pingo Doce</td>\n",
       "      <td>0.300</td>\n",
       "      <td>13.30</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2026-10-02</td>\n",
       "      <td>Pingo Doce</td>\n",
       "      <td>Tablete de Chocolate Biiig Cookie Pingo Doce</td>\n",
       "      <td>0.300</td>\n",
       "      <td>13.30</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2026-10-02</td>\n",
       "      <td>Pingo Doce</td>\n",
       "      <td>Tablete de Chocolate de Leite com Caramelo e A...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>14.97</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2026-10-02</td>\n",
       "      <td>Pingo Doce</td>\n",
       "      <td>Tablete de Chocolate de Leite e Cheesecake de ...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>14.97</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2026-10-02</td>\n",
       "      <td>Pingo Doce</td>\n",
       "      <td>Tablete de Chocolate de Leite e Oreo Milka</td>\n",
       "      <td>0.300</td>\n",
       "      <td>14.97</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data       Local                                            Produto  \\\n",
       "10 2026-10-02  Pingo Doce     Tablete de Chocolate Biiig Amendoim Pingo Doce   \n",
       "11 2026-10-02  Pingo Doce      Tablete de Chocolate Biiig Biscuit Pingo Doce   \n",
       "12 2026-10-02  Pingo Doce       Tablete de Chocolate Biiig Cookie Pingo Doce   \n",
       "51 2026-10-02  Pingo Doce  Tablete de Chocolate de Leite com Caramelo e A...   \n",
       "60 2026-10-02  Pingo Doce  Tablete de Chocolate de Leite e Cheesecake de ...   \n",
       "62 2026-10-02  Pingo Doce         Tablete de Chocolate de Leite e Oreo Milka   \n",
       "\n",
       "    Embalagem  Preço por kg/l  Custo de compra  \n",
       "10      0.295           13.53             3.99  \n",
       "11      0.300           13.30             3.99  \n",
       "12      0.300           13.30             3.99  \n",
       "51      0.300           14.97             4.49  \n",
       "60      0.300           14.97             4.49  \n",
       "62      0.300           14.97             4.49  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chocolates_p[(chocolates_p['Embalagem'] > 0.26) & (chocolates_p['Preço por kg/l'] < 15)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
